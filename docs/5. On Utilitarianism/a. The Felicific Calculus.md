## The Felicific Calculus 
##### (Utilitarianism in Theory & History)  

Everything in AI Alignment hinges around the question of what the AI’s “utility function” will be allowed to be. It is thought that AI will emerge like so: it looks at the state of The World. It runs some stupendously, repulsively complex mathematical function to discern: what action in The World shall I take in order to maximize my utility function? It weighs all possible actions with a floating point value from zero to one according to the utility function and chooses the one which is the highest. At every step of action, it does this once more, accruing more and more Utility each time.

Everything hinges on what exactly this Utility function represents. In the infamous case of the paperclip maximizer, the AI’s Utility upon taking a given action corresponds directly to how many new paperclips will be produced by carrying that action out. The rogue AI subordinates all other concerns for this, such as whether, in the process of it assembling paperclips, land for paperclip factories, steel for paperclip-assembling machinery, people remain alive or dead.

The project of AI Alignment is to create a “Friendly AI”, which would have a mathematical function which formally represents something along the lines of “human values”, “maximize whatever we truly ultimately care about”, “truth-beauty-goodness maximizer”, so we can just let the machine rip and gain increasing amounts of perfect happiness and bliss forever.

The seeming impossibility of mathematizing this is why AI Alignment is declaring failure and imminent doom.

There’s an obvious question here. Why are we supposing that we can put a single number on people’s desires? Why are we assuming that what people want can be measured? There is a sort of insanity in this assumption, isn’t there? Isn’t it a deep overextension of the tools of engineering and scientific practice to imagine that we could hold up a measuring tape to joy and beauty and tell you to five places of decimal precision exactly how much these things are desired? Is this not the ultimate prison-factory, the ultimate false inscription of desire?

Perhaps. The idea that an AI might “have a Utility function” takes on two registers here. In the first, there is the possibility that we actually implement this into the AI, we establish a concrete function of valuing, look, this is its Utility function, here, we wrote it out in code. In the second, there is the concept from Von Neumann and Morgenstern that everything can be described as having a Utility function, whether it wants to be described that way or not. We either inscribe one in the AI ourselves, or else it will surprise us with something bizarre and fantastic of its own design, but it will still be a Utility function.

How can Von Neumann and Morgenstern make this claim? Do you feel as if you have a Utility function? Do you know what you are maximizing yourself?

Already, in earlier sections of this essay, we have explored the idea that, really, no one has much of a sense of what they want. Our desires are constantly shifting, falling apart, dissolving; we find ourselves questioning what we want even as we speak it aloud in a sentence.

Even worse, certainly, is the problem of deciding what *humanity* wants. If we cannot find a stable coherent desire within one person, how are we supposed to do this across and amongst seven billion? Yudkowsky will often talk about attempting to define what he calls humanity’s “coherent extrapolated volition” (CEV), ie humanity wants something, but doesn’t know how to make this desire coherent… but what if it did, and it was possible to extend this desire indefinitely in the future?

It seems obvious to us that no such thing exists. Humans have at least seven billion definitions of what the good is. We might collectively approach some convergence on this, but not without some dramatic process circulating across the globe as people attempt to collectively define this, a process of which we find hard to imagine an end. We now in the Western world nigh unanimously believe that slavery is evil, but to come to this collective conclusion, half a million people had to die in a war. Yudkowsky’s ideas for establishing CEV include asking an AI to simulate councils of humans debating ethics for hundreds of years until they come to some kind of conclusion, which seems a little ludicrous, but a better idea doesn’t exactly spring to mind.

To understand from where the concept of denominating all desire in a single floating-point number derives, we have to investigate the history of *utilitarianism*. Primarily, this emerges through the succession of three figures: Jeremy Bentham, John Stuart Mill, and of course, as we have been discussing, Von Neumann.

Jeremy Bentham was the type of man who would probably be posting on LessWrong if he was living today. He was a fervent social reformer, constantly posting essays appealing for some reform of the law, unafraid to make radical, shocking proposals. His general view of the world was one in opposition to nearly all moral grounds that had hitherto been established: Biblical justifications, classical virtues, natural law, natural rights. He was also opposed to the gross complexity of all the overlapping English legal traditions and appealed for a great simplification of the law.

Bentham’s idea was to base all moral decisions on mathematics. The basic axioms of utilitarianism are very simple. It is clear to Bentham that all anyone can do is to seek pleasure and avoid pain. When one acts in this manner, it is called acting according to one’s Utility. This is not just a way we could conceive of people acting, it is how everyone actually does act; there is no other way they can possibly act. Thus, to Bentham, basing the law on a simple understanding of the pleasure-pain binary is an exercise in clarity.

Bentham had the idea that the pleasure or pain that various actions cause could be quantified, and called this the “felicifc calculus”. He breaks down the logic of the felicifc calculus in great depth, describing how one can calculate the value of a pleasure via establishing its duration, its likelihood of occurring, its intensity, its likelihood of being followed by further pleasures, and several other factors. He recommends that lawmakers base all their decisions of what laws to implement through considering the felicifc calculus — what he neglects to mention is the question of how these pleasures are actually able to be measured and meaningfully quantified.

A few years after he was to originally describe the felicific calculus, Bentham discovered a project which would become his other lifelong obsession: a proposed architecture for a new type of prison called the Panopticon. The prison consisted of a ring of cells with see-through roofs, in the center of which would be erected an elevated guard-tower. The guard sitting in the center would be able to observe any prisoner he liked at any moment.

The idea was originally his brother’s, but Bentham took it up in great earnest and would for thirty years petition the English government to implement his design. He believed in the proposal so strongly that he offered to serve as the warden of the prison himself for no pay — sitting in that guard tower alone, peering over all of the inmates. Bentham believed that the architecture of this was enough of a general-purpose solution for misbehavior that he suggested it be also be built for factories, hospitals, schools, and mental asylums. If people lived in buildings built like this, they would conform to moral behavior, for they would not need to actively be observed to act like they are observed, they would simply have the sense that they might be observed at all times. Bentham believed this sense of being constantly monitored would be good for the citizen.

Bentham, despite being a disciplinarian of sorts, obsessed with prisons, also has a strange paradoxical quality of being a libertine hedonist. He would advocate that, according to the felicific calculus, if a sex act cannot be considered to cause net harm, it should not be condemned. He would be one of the first rhetoricians in England to argue for the legalization of “unnatural” sex acts like masturbation, homosexuality, even pederasty.

But the use of the felicific calculus creates some problems for the masturbator. Bentham uses various expressions to describe the sex acts he believes should no longer be off-limits: “Act between two persons of different sex, one of whom is married”, “Act using an organ which is not susceptible of impregnation”, “Act involving two or more females”, etc. It is interesting that he does not describe them via the terms that these are usually known: adultery, sodomy, lesbianism. This is because condemnation is implied in these terms, some sort of judgment from the community, tradition, or God. But Bentham wishes to question this method of judgment entirely. He who engages in unnatural sex acts is not able to appeal to any sort of judgment of the commons to delineate the normalcy of what he might do. Rather, he must have some sort of awareness of all bodies which the sex act might affect — it is like he must be situated himself in the Panopticon in order to perform this calculus. Thus, the masturbator becomes a true pervert, a voyeur, involving the public in his sex acts, for it is impossible to consider the act without involving them.

Bentham’s best friend and greatest follower later in life was one James Mill, an economist and philosopher whose best known work is *The History of British India*. This volume is notable for being one of the first books which set out to write a history that was overtly critical and moralistic rather than attempting to describe its subjects neutrally, and was ruthlessly critical of both the Indians and the British. James Mill used the Benthamesque logic of moral critique to excoriate the traditions of the Hindus, calling them backwards and superstitious, lacking in a logic which would lead to the general good. Upon publishing this work, Mill would become enormously influential within Indian affairs, and would be offered a post in the British East India Company as an examiner of correspondence. Something along the lines of Bentham’s rejection of traditional moral structures and proposal for an imaginary calculus to rationalize everything in its place would turn out to be a convenient background assumption for how India was to be governed.

When James had a son, John Stuart Mill, he and Bentham took the opportunity to attempt to raise the child as a model philosopher of the Benthamite calculus. John Stuart was homeschooled and prevented from socializing with other children and given philosophy texts. J.S. Mill would go on to fulfill his father’s ambitions for him with great excellence, inventing the term utilitarianism and placing it within a much more widely accessible discourse that the eccentric Bentham could not establish. J.S. Mill outlined a variety of qualifications for utilitarianism which avoided some of its more extreme conclusions implied by Bentham, giving room for principles of justice, and making a gap between the higher and lower pleasures.

J.S. Mill was offered a position as a colonial administrator of the British East India Company at only seventeen years of age. Mill was a fervent advocate for liberty, especially economic liberty, advocating strongly in Adam Smith’s argument for free markets. But he also argued for a form of “benevolent despotism” administered by the British East India Company, specifically for India, because he believed the inhabitants of the colony to be too naive and backwards to govern themselves. If they were to determine their own affairs, it would certainly not be rational, not leading towards the greater Utility of all in the way an Englishman might govern, and so on.

We can see here the type of environment in which utilitarianism emerges: one of laissez-faire capitalism and colonial administration. It is clear that the theory of utilitarianism could have never been conceived of prior to banking, accounting, and so on, as it imagines the moralist as a grand Accountant who is able to check in and evaluate the health of everyone’s accounts as they cash in on their pleasures.

But the development of capitalism is not enough for the utilitarian fantasy to emerge, because the utilitarian moralist is not quite just like a capital owner taking stock of his resources in his business account. If he was, he would be extracting profits from the ones which interest him, and dispersing with the rest. But the utilitarian moralist maintains an essential relation with all subjects; he cannot merely reject the ones who he dislikes, he must understand them to remain in their quest to seek their own happiness. Rather, he is like the colonial administrator who governs on laissez-faire principles, allowing each individual to seek his own ends, though at the same time for his own profit — the East India company has its own share price to maximize — which is ultimately accounted by their accountants and measured as the global Utility of the system.

As he the Company accountant is disinterested in any economic activity that does not ultimately benefit him, the “freedom” he allows his subjects is not true freedom, as that would potentially include barbaric or superstitious or perverse behavior. The free actions he wants to see are those which are rational, that is to say economic, this is to say, can be measured. But this rationality does not already exist beforehand; the field for all this must be created. He believes he must construct this field, the field over which it is possible to perform the felicific calculus, for his subject’s own good.

We live in a world where it is conceived of that all desire can be valued in a single denomination: money, or the US dollar. Proponents of rational choice liberalism, following VN&M, will argue that if the global market is efficient enough, the relative price of goods will be collectively adjusted to match exactly how much these things are desired, thus creating a 1:1 system of accounting for our wishes and demands.

But this is of course not how it works exactly in practice, there is all sorts of slippage. The best artists completely fail to make money, bands are better before they sell out. This is always the tragedy of industry; the artisan wishes he could make bespoke handcrafted goods and be entirely true to his craft, but he is forced into the logic of crude commodity production, sowing Minions and Dogecoin patterns onto sweaters because one has to go with what sells. People speak empty words to make money instead of the truth, people praise their sponsors, everyone has something to sell, everything seems fake. Somehow, this accounting system is messing everything up. We are happiest when we can forget about it, when we can go for walks to nowhere in particular, give each other stupid ugly gifts infused with love.

But to the accountant, the banker overseeing our assets, this is not relevant. When I am trying to sell my house, he does not factor in how much joy was experienced each day cooking breakfast in the kitchen, the kisses shared as I sent my wife to work in the morning and as I tucked my children in to sleep, the pain my neighbors might experience when seeing me leave.

We see here a slippage from the true value of the thing, as experienced by the human in his day-to-day lived bliss, and the ability of this feeling to be captured by the accountant, in numerated form. A price tag on every cracker eaten, every fly swatted at, every kiss stolen. Thus, for Yudkowsky’s Utility maximizing AI to be aligned with man’s desires, he would have to be like “the perfect accountant”. He would have to measure and take perfectly into account all things. This is something that the believers in Singularity generally believe to be not just possible to emerge soon, but likely.
