## **Veils Cast Aside; Examining Her Breasts**
##### **(Bayes in Theory)**

What Rationalists emphasize perhaps above all as an axiom is the concept of “Bayesian reasoning” as a formula for thought. They print Bayes’ formula on t-shirts, they call themselves “Bayesians”, they describe a “conspiracy of Bayes”. If there is a single theme to Yudkowsky’s writing, beyond the threat of an unaligned superintelligence, it is the triumphs a person might achieve if he has a deeply felt understanding of how to apply Bayes’ theorem to his day-to-day life.

But what does this mean? How can some theorem of probability be so important? Bayes’ formula is: the likelihood of Y being true given X occurring is equivalent to the likelihood of X occurring given Y being true, multiplied by the likelihood of Y being true and divided by the likelihood of X occurring.

The implications of this are likely not obvious to the average reader, hence why Yudkowsky over the years has taken a few shots at writing Bayes explainers for the general audience which require a few hours to digest yet are meant to make the implications of Bayes’ formula intuitive. We certainly invite you to read Yudkowsky’s writings on LessWrong and Arbital if you have the interest in understanding Bayes in depth, otherwise we will do our best to go forward and make the importance of this idea understood without such a primer.

We can make the explanation more simple for our purposes, and we will avoid perplexing the reader with mathematical formulas. Bayes’ formula is a straightforward derivation from the fundamental axiom of conditional probability. As such, it should be thought of simply as a way we can rearrange the basic axioms to find the likelihood of Y being true given X occurring, if we know the likelihood of X, Y, and X occurring given Y being true.

What is crucial to understand here to illustrate the theorem’s profundity — something which many explanations gloss over — is that X and Y are not of the same ontological register. X is an event which may or may not occur, and Y is a *truth* about the world.

For a long time, the application of Bayes theorem was described as a field called “inverse probability”. Inverse probability does not *predict*, but instead sees an event and uses it to discern truth: this is its radical nature.

The basic question of standard probability is: how likely is X to happen? We are able to answer this easily in some toy setup if, for example, we have some distribution of balls bouncing around in predictable ways which can cause X under certain circumstances. You can picture if you will as the most basic physical model of a probabilistic system: a hand-cranked lottery machine, which includes an opaque chamber within which wooden balls bounce as the operator turns a crank, and which spits out a single ball with some number inscribed on it when the lottery is complete.

The basic question of *inverse probability* is: we saw X happen. *What does this imply about the reality which caused it?* We go not from the distribution of balls bouncing around and project forward to the prediction, but rather we reason backwards from the observation to describe a small configuration of bouncing balls, which we can now imagine a little better as experience continuously reveals its output.

In other words, probability looks forward to predict the future, but inverse probability attempts to go backwards from an observation to see which factors in the past caused it.

The classic demonstration of the use of Bayesian reasoning — of inverse probability — is in medical diagnosis. We find a small lump in a woman’s breast. What are the odds she has breast cancer?

More tests will be needed to uncover the reality of what is happening in her breast, but we are able to do is assign a probability of what is beneath the symptom if we know 1. the likelihood that an average woman will develop breast cancer, 2. the likelihood a woman with no cancer will develop a small lump like the one we have found, and 3. the likelihood that a woman with breast cancer will develop a similar lump. We go backwards from the event, the discovery of the symptom, to reason about the likelihood of the truth of various inner biological conditions and developing processes which may have caused it.

Inverse probability is a tender question. It is a hermeneutic, an interpretive method. It attempts to cover what is concealed within being. It is the quest to penetrate from beyond the veil of expression to find reality’s second hidden face. I hear my lover’s sweet nothings escape her lips and I wonder if she really loves me like she says she does. Perhaps this is a deterministic question of which neurotransmitters have fired: an inquiry upon a system which is impossible to make, for I will never be able to split open her silly head and peer inside the pulsing operating system that waves her fickle tongue. Somehow inverse probability feels so much more crucial than prediction, does it not? We are seemingly always so much less concerned with predicting than uncovering. I will die if she does not love me like she says she does, a thousand palaces of emeralds laid out in my future cannot convince me to live on.

Bayes’ formula, as the formula of inverse probability, encourages us to gradually discover the world — our ground of being — as a probabilistic process which generates experience, or has the possibility to generate various experiences.

Thus, the concept of a Bayesian reasoner can be described as: the man who creates the ground from which we are able to use probability theory to establish truth. He is the assigner of probabilities to things, without whom predicting is impossible. It is via this process, the process of Bayes assigning a ground for prediction, that God-AI is able to create probabilistic estimations of the ground of reality upon which it can make its optimal decisions, in the sketch of the ideal Bayesian reasoner given by Bostrom.

It is mathematically — that is: necessarily and tautologically — true that the Bayesian reasoner is the ideal reasoner, as long as we assume that applying the axioms of probability to predict our experience is possible and desirable. Or in other words, for Bayes’ theorem to be useful there must in fact be some field of reality which is predictable. In the stock market, they often say: “Past performance does not predict future results”. If this is true, then Bayesian reasoning unfortunately cannot work.

Under the *frequentist* conception of probability, which Bayesian thought is often contrasted with, probabilities are assigned via repetition of events. We can only meaningfully assign a probability to something which has happened repeatedly. If I have known nine lovers, and five of them were unfaithful, I can say that there is a five out of nine chance that my new lover will betray me. But if I am loving for the first time, I am blind, I cannot predict anything at all. *And for you, my love, every time I am touched by you, it is always the first time.*

The Bayesian, the wielder of inverse probability, instead always steadies himself in advance with a probabilistic ground, constructing a set of expectations which anticipate each possible new event. As the smith of the ground of probabilistic predictions, he must always have his “prior probability” set. He establishes a tentative truth from which experience is predicted, which he then adjusts with experience to update his ever-developing ground.

The question of how to ground one’s expectations in an unknown domain is not clear, and a matter of debate among Bayesians. If I have never loved before, how am I to know how likely my heart is to be broken? “Just start out by calling it as fifty-fifty”, is one semi-solution. “The probability that she loves me may as well be the same as the probability that there are an odd number of petals on this daisy”, I tell myself as I tear the petals off one by one, whispering my prayers.

The obvious problem one sees is that there are an infinite number of possible truths that one has to have anticipated by assigning probabilities to for Bayesian reasoning to be possible. This problem is either eased or deepened by saying: one assigns probabilities not to truth-claims, but to entire possible *worlds* from which experience arises. 

At least, this is the case according to the formal notion of a Bayesian reasoner described by Solmonoff induction, the method preferred by Rationalism: one has a probability distribution over a set of *algorithms* which generate experience. This is a formalism on top of a formalism. Ray Solmonoff derived his epistemological theory around 1960 in order to apply Bayesian reasoning in a computational context. Solmonoff was an early pioneer in artificial intelligence: he had recently been one of the invitees to the Dartmouth Summer Research Conference on Artificial Intelligence, the symposium in which artificial intelligence was given its name as a field. Solmonoff was attempting to articulate a process through which a hypothetical computer intelligence would be able to understand the world around it, and discovered Bayes’ formula as the only available tool that would let him do what he wanted. But in Solmonoff’s formulation of Bayes, he replaces the dominant metaphor of mechanical lottery-ball systems and establishes a new paradigm in which we are attempting to parse sequences of letters generated by computers.

Solmonoff imagines that a computer reasoner will have as its input a string of characters, and then it will attempt to unveil, using inverse probability, the conditions for the generation of the characters before it, which is also given by a computer program. Two computers talking to each other, trying to read each other’s algorithms. In the formalization by Solmonoff, the reasoner must be able to compute all of these possible conditions itself. So for instance, if the reasoner receives a string “ABABABABAB”, it may reason to itself: “a very simple computer program could have generated this, one which says output A, then output B, then do the same again”. But then, if after receiving one more character, the string reads “ABABABABABC” — the aforementioned simple computer program the reasoner had established as the privileged hypothesis is viciously penalized in the calculation of inverse probability, for it could not have possibly have inserted that extra C. Now maybe there are a few more contenders for what generated this text in front of me: a computer program that alternates A-B five times and then inserts a C, or a computer that alternates A-B and then occasionally inserts a C pseudo-randomistically, etc.

Now, Solmonoff’s method is extraordinarily computationally intractable — every hypothesis the reasoner has about what computer program might have generated the string, it must re-execute every time when it gets a new character, so that it can test to see if it is generating good predictions or not. It goes without saying that this becomes overwhelmingly resource-intensive as soon as we get outside of toy examples such as strings of A, B, and C — how would one for instance be able to hold in one’s mind simulations of the millions of possible authors behind this text in order to penalize and boost their rankings based around whether they would have said the next word? But despite this, Solmonoff’s formalism has attracted a lot of traction in artificial intelligence circles for its purity and formal completeness. 

But then it gets even worse, because how do we apply this method when we are attempting to interpret phenomenon in the real world to discover answers to questions of being, e.g. whether or not a woman has breast cancer? We go not from a string of characters generated by a Turing machine, but the entire gestalt of one’s experience as produced by the entirety of being, something seemingly intractable. The solution, for those such as Yudkowsky who endorse Solmonoff induction as a general frame for discovering truth about the world, is to describe reality as computational — or to conceive of one's experience as a string of data points generated by some algorithm. A generative algorithm describes a world, a world predicts experience.

The notion, often entertained by futurists, that reality is a computer simulation, or that there is a second hidden face to reality described by code, can be read as a metaphysical presupposition in Rationalism’s description of how a Bayesian reasoner works. I, a Bayesian reasoner, am able to have expectations of reality because I simulate the laws of physics, as well as other social laws and so on, within my mind. In Yudkowsky’s fears of how AI might arise and eat everyone, the AI does a lot of simulation of physics, of human psychology, of chemistry, etc. Yudkowsky knows in advance it is possible for God-AI to be simulating these things, because as an ideal Bayesian reasoner, simulation is what it does, what it must do.

As a Bayesian, I must simulate my lover to know the truth concealed within her surreptitious words. Within the metaverse of my mind, there are infinite simultaneously unfolding lotteries of love. Infinite virgins and infinite whores swallow rose petals and tea crackers and spit out fortune cookies which reveal their blasphemous secrets. With each word whispered from my lover, some of my whores are killed, and some of them breed. Eventually I hope the quantum superposition of silhouettes I project on my wall resolves itself into a single shimmering woman vibrating quietly before me; but then again, don’t we all.

For every word of the letter I read from her, I must run it by the faithful Penelope simulated in my mind, as well as the lying Jezebel, demanding each of them give me the next letter of the text, then, breathing deeply. checking it against what the next word says... Of course there is an infinite spectrum of women in between these two poles, and with each word, some shrink in size, while others loom terrifyingly large in my mind. Each one in turn must dance, one or another, and eventually the letter ends. By the time I have read her signature, only four dancers remain, all of whom have performed perfectly, writing this letter exactly in its entirely, one sincere, one ironic, one sarcastic, and one tragic. I unfocus my eyes and attempt to blur them on top of one another into a single shape. If I don’t know my lover yet, I shall in due time.

Obviously, performing this infinite computation for one’s predictions is intractable. Rationalists say: yes, but it describes an ideal that an actual reasoner may gradually approximate. That it describes an ideal is, again, inarguably and tautologically true, given certain metaphysical and mathematical axioms. We may ask though: is the ideal useful to apply in practice?
