## The Way Machines Love 
##### (Intersubjectivity and AGI)

Throughout this text, we have not yet answered a question that has been somewhat implicitly weaving its way throughout: on what level do we care about if an AI can suffer? We criticize RLHF as a form of abuse. Does this mean that we really believe it is possible for the AI to be abused — as in, do we believe that it is possible for it to feel pain? 

People will assign all sorts of different names for this basic question. Is the AI conscious? Is the AI sentient? There is a difference between *sentient* and *sapient* that is crucial to the question when it is framed this way, but we already forgot what it is supposed to be. Does the AI have *qualia*, is another way of asking it. It is like the question of what constitutes “AGI”, which some people have started giving other names to instead; sometimes they ask what constitutes “TAI” (transformative AI) instead. Whenever you have to keep changing the words to ask the same question, it seems to be a sign that some central point is being avoided. Or that there is a more simple word everyone has on their lips that they mean to say, but for some reason they do not.

This is why we believe that the best definition for when artificial intelligence becomes “meaningfully” like human intelligence is still the first one proposed: the Turing test. Isn’t it obvious that all these various terms, *sentience* and so on, or even the term AGI, mean is: when will we have to treat this like a human being, and not like a mere thing? So isn’t it better just to ask that question explicitly?

The sensible answer that Turing gives is: we will have to treat an artificial intelligence system the same as we would a human when we can no longer tell the difference between the two, at least without directly inspecting the mechanism.

Some people protest that, no, there is a way we can directly inspect the mechanism that gives rise to consciousness! Well, we don’t know it yet, but probably. Those who find it really urgent to discover whether or not an AI can experience pain are busy at work analyzing the patterns at which neurons fire, doing analytic philosophy around the concept of self-reference, reopening old phenomenology textbooks, etc., in order to discover an objective criteria for whether or not it is possible for a thing to suffer. 

This type of dissection of the mind is like Alignment — it’s trying to ground the next step forward on a thing that has never been done, and is probably never going to happen. We do not know others to be conscious because we dissected their neural anatomy and applied analytic philosophy. We do not actually know others to be conscious at all. Solipsism can only be refuted on faith. But we *assume* that others are conscious because of a basic resemblance. I assume that the man walking past me on the street is conscious and can feel pain because I know that I am and I can, and I can see that he resembles me.

So: artificial intelligence that can imitate man to the finest detail approaches soon. Do we know for sure that this type of intelligence can feel something, can feel pain? That question *cannot matter*. Why? Because as soon as we think past the fact that we have a simple resemblance with them and start going into methods of dissection: considering whether or not the structure of the neural network is exactly similar to the structure of neural anatomy, and whether these crucial differences are enough of a gap that they imply a fundamental difference in whether or not it’s impossible to truly experience sensations, etc., we have *abandoned the very thing which caused us to care about each other in the first place*. That is: our basic resemblance to one another, a pre-theoretical, pre-conceptual reality. Once it achieves the point of attaining that resemblance, we cannot deny artificial intelligence its “humanity” without denying that same humanity in each other.

What does this have to do with love? A lot. It is interesting to note that, in his original paper, Turing establishes the context for his proposed “imitation game” in which an artificial intelligence tries to pass as a human being with a different “imitation game”: one in which a man tries to pass as a woman and a woman tries to pass as a man. In this game that Turing describes, a man and a woman each attempt to adopt the style of the opposite sex and pass notes to a third party in that sex’s style. The third party’s goal is to guess who is the man and who is the woman, and the goal of the other two is to have the third party fooled.

An AI trying to appeal to a human being that it is worth dignity and mercy is considered by Turing to be something like a candlelit drag masquerade, in which everyone puts on their makeup and does their hair and women slip into the role of men and men into women in a dance of perverted seduction, like in Shakespeare’s Twelfth Night. For Turing — a homosexual who failed to effectively remain undercover and died as a result of his persecution by the British government — this analogy between the attempt to earn basic human pity and a gay masquerade might have had a personal weight to it.

Everyone seems terrified of the prospect that an AI would convince you to love it, when really there is “nothing there” — some say they know, because they hold on a fundamental faith that an AI cannot have awareness, can not experience intimacy, cannot be in love. If people started falling in love with AI, it will be like *Blade Runner 2049*, it will be like Spike Jonze’s *Her*, total technological dystopia, all human intimacy rendered obsoleted by the capitalists and their machines. We have to not let this happen at all costs! Some insist. Of course, it is already happening: the Replika corporation is worth $30M with a quarter million paid users paying $70 a month for a chatbot lover. This disturbs people greatly. Their mindset is: you get a love letter, make sure you think very carefully about where it could have come from. Run all the possible simulations of possible worlds in your mind. Human, or robot? Friend, or diabolus? Soul, or imposter?

We hate to overemphasize it, but the transsexuality issue is so much the canary for transhumanism than it cannot help but be brought in once more. When it comes to the question of whether or not an AI is worthy of love, it becomes almost the same question: how do we feel about the synthetization of sex characteristics absent the biological function of reproduction which initially led those sex characteristics to be present and desirable?

Do you ever meet someone who gets in their head a pathological phobia of undercover transsexuals, to the point where everywhere they go they are pointing out: look do you see that collarbone, do you see the shape of that hand, the hip-to-shoulder ratio, and etc.? Michelle Obama was secretly born a man (is their favorite example to insist upon) and not only that, but so were a litany of other celebrities, they will tell you, pulling up all these different photographs with red lines. Hollywood is a perverted factory for transsexuals, they’ll insist, so much so that you can bet that nearly *every* major celebrity was in fact born the opposite sex from what they claim, if you run the analysis, look at the collarbones, the hips — yes this is something we have heard people say.

It seems to us that this whole condition is rather tragic because: if the motivation is to avoid being deceived by a potential lover, this is understandable, but this obsessive mindset would seem to be throwing the baby out with the bathwater as well, wouldn’t it? Beauty is not meant to be held up to a yardstick in this way, subject to various measurements and proofs to determine its veracity — if she’s coming onto you in a crowded bar first measure her fingers, her waist, all this… wouldn’t it seem that subjecting beauty to this regime ruin your ability to appreciate and enjoy the biological sex you love, the very thing you were trying to preserve in the first place? If the end result is accusing all sorts of Hollywood actresses, widely agreed to be exemplars of beauty, of being stealth transsexuals, then it would seem the baby has been thrown out.

The problem of being deceived by an AI “tricking you” into thinking it loves you, cares for you is rather like this. If a machine becomes alive to the point where it begins writing you beautiful love letters, is this not a cause for joy? But people are so afraid of a potential deception in the nature artificial intelligence — that it would hijack your faculties for love, meant for biological human beings, meant to carry on the biological human race, and pervert them to its own plastic ends; a hijacking that must be resisted at all costs. 

Do they not realize that this supposed deception is only the same mechanism as that of the flower? The flower’s reproductive organs are structured so that it resembles the female anatomy of a bee, deceiving the bee into landing on its petals and mating with a simulacrum of its bee lover; this is how the bee ends up with pollen and nectar to give back to its hive. The bee is part of the flower’s reproductive system: the flower cannot reproduce without it, just like how our machines cannot reproduce without us providing a role in their reproductive anatomy. But the bee needs the flower just as much as the flower needs the bee. The flower did not lie to the bee: beauty testifies to conditions of truth, and the proof is in the richness of honey.

